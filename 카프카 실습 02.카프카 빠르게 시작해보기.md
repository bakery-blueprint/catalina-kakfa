# 02.카프카 빠르게 시작해보기

* 실습책 : 아파치 카프카 애플리케이션 프로그래밍 with 자바 (데브원영)
* 목표 : 실습용 카프카를 설치하고, 명령어를 활용하여 토픽을 생성, 수정하고
  	     데이터를 전송(프로듀서)하고 받는(컨슈머) 실습.


## 1. AWS EC2 인스턴스 생성

 

## 2. 인스턴스에 접속

	(윈도우 전용)
	putty 실행 후 뜨는 Putty Configuration 팝업창의 Connection - SSH - Auth 에서 
	Private key file for authentication 에다가
	puttygen 으로 generate한 private key file 넣은 후 아래 정보로 접속


	IP Address : 34.227.194.82 (개인별로 생성한 AWS EC2 인스턴스 퍼블릭 IPv4 주소)
	Port : 22

	login as : ec2-user



## 3. 인스턴스에 자바 설치

	1) yum을 이용한 openjdk 설치
		```
		(EC2 인스턴스에서)
		$ sudo yum install -y java-1.8.0-openjdk-devel.x86_64
		$ java -version  (설치된 자바 버전 확인)
		```



## 4. 주키퍼, 카프카 브로커 실행

	1) 카프카 바이너리 패키지 다운로드 (카프카 브로커 실행을 위함.)
		```
		(EC2 인스턴스에서)
		$ wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz
		...
		$ tar xvf kafka_2.12-2.5.0.tgz
		...
		$ ll   (압축해제 확인)
		..
		$ cd kafka_2.12-2.5.0
		```

	2) 카프카 브로커 힙 메모리 설정
		```
		(EC2 인스턴스에서)
		$ export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
		$ echo $KAFKA_HEAP_OPTS   (옵션설정 확인)
		-- 여기까지만 하면 터미널 세션 종료시 초기화되므로 아래 파일에 덮어써야 함.

		$ vi ~/.bashrc
		-- 하단에 export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m" 입력 후 esc -> wq! 로 저장.

		$ source ~/.bashrc  (스크립트파일 즉시 반영)
		$ echo $KAFKA_HEAP_OPTS
		```

	3) 카프카 실행 스크립트 내부에서 메모리 설정부분 확인하기
		```
		(EC2 인스턴스에서)
		$ cat bin/kafka-server-start.sh
		```

	4) 카프카 브로커 실행 옵션 설정
		- 실습용 카프카 브로커 실행할 것이므로 advertised.listener 만 설정함.
		  (카프카 클라이언트 또는 커맨드 라인 툴을 브로커와 연결할 때 사용됨.)
		- 이미 실행되고 있는 카프카 브로커의 설정을 변경하고 싶다면 브로커를 재시작해야하므로 신중히 설정해야 함.
		```
		(EC2 인스턴스에서)
		$ vi config/server.properties
		  -- advertised.listener 주석 해제 후 본인의 EC2 인스턴스 IP 입력하여 수정.
		```

	5) 주키퍼 실행
		```
		(EC2 인스턴스에서)
		$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
		$ jps -vm
		```

	6) 카프카 브로커 실행 및 로그확인
		```
		(EC2 인스턴스에서)
		$ bin/kafka-server-start.sh -daemon config/server.properties
		$ jps -m
		$ tail -f logs/server.log
		```


## 5. 로컬 컴퓨터에서 카프카와 통신 확인

	1) 카프카 명령어를 실행하기 위한 쉘 설치
	   Windows : WSL설치, 우분투 설치 (https://docs.microsoft.com/ko-kr/windows/wsl/install)
	   Mac OS :  zsh 기본제공이므로 별도 설치 필요 없음.

	2) 카프카 바이너리 패키지 다운
		```
		(로컬에서)
		$ curl https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz --output kafka.tgz
		$ tar -xvf kafka.tgz
		$ cd kafka_2.12-2.5.0
		$ ls
		$ ls bin
		$ bin/kafka-broker-api-versions.sh --bootstrap-server 34.227.194.82:9092 (본인 인스턴스 IP입력)
		```
		(윈도우일 경우 우분투에 jdk설치해야 위 과정 진행 가능. https://i5i5.tistory.com/266 참고.)

	3) hosts 파일 설정
		```
		(로컬에서)
		$ vi /etc/hosts

		34.227.194.82	my-kafka  (본인 인스턴스 IP입력)
		```


## 6. 카프카 커맨드 라인 툴

	1) kafka-topics.sh
		- 토픽과 관련된 명령 실행 가능. 토픽은 RDBMS에서의 테이블과 유사한 개념.

	2) 토픽 생성
		```
	 	(로컬에서)
		$ bin/kafka-topics.sh \
		--create \
		--bootstrap-server my-kafka:9092 \
		--topic hello.kafka \
		```

	3) 토픽 복수 생성
		```
		(로컬에서)
		$ bin/kafka-topics.sh \
		> --create \
		> --bootstrap-server my-kafka:9092 \
		> --partitions 3 \
		> --replication-factor 1 \
		> --config retention.ms=172800000 \
		> --topic hello.kafka.2 \
		```

	4) 토픽 리스트 조회
		```
		(로컬에서)
		$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
		```

	5) 토픽 상세 조회
		```
		(로컬에서)
		$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2
		```

	6) 토픽 옵션 수정
		```
		(로컬에서)
		$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
		> --topic hello.kafka \
		> --alter \
		> --partitions 4 \

		(로컬에서)
		bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
		> --topic hello.kafka \
		> --describe \

		(로컬에서)
		bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
		> --entity-type topics \
		> --entity-name hello.kafka \
		> --alter --add-config retention.ms=86400000 \

		(로컬에서)
		bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
		> --entity-type topics \
		> --entity-name hello.kafka \
		> --describe \
		```


## 7. kafka-console-producer.sh
	생성된 hello.kafka 토픽에 kafka-console-producer.sh 명령어를 사용하여 데이터를 넣을 수 있음.

	```
	(로컬에서)
	$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka
	>aaaaa
	>bbb
	>c 
	... (자기가 등록하고 싶은 데이터 입력 후 ctrl+c 로 종료)

	(로컬에서)
	$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka \
	> --property "parse.key=true" \
	> --property "key.separator=:"
	>key1:no1
	>key2:no2
	>key3:no3
	> (ctrl+c 로 종료)
	```


## 8. kafka-console-consumer.sh
	hello.kafka 토픽으로 전송한 데이터를 kafka-console-consumer.sh 명령어로 확인할 수 있음.

	```
	(로컬에서)
	$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka \
	> --from-beginning

	(로컬에서)
	bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \
	> --topic hello.kafka \
	> --property print.key=true \
	> --property key.separator="-" \
	> --group hello-group \
	> --from-beginning
	```


## 9. kafka-consumer-groups.sh
	컨슈머 그룹으로 생성된 컨슈머로 토픽의 데이터를 가져간 경우 아래 명령어로 확인.

	```
	(로컬에서)
	$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list

	(로컬에서)
	$ bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 \
	> --group hello-group \
	> --describe group
	```


## 10. kafka-verifiable-producer, consumer.sh
	kafka-verifiable로 시작하는 2개의 스크립트를 사용하면 String 타입 메시지 값을 코드 없이 주고받을 수 있음.
	간단한 네트워크 통신 테스트 할 때 유용함.

	```
	(로컬에서)
	$ bin/kafka-verifiable-producer.sh --bootstrap-server my-kafka:9092 \
	> --max-messages 10 \
	> --topic verify-test

	(로컬에서)
	$ bin/kafka-verifiable-consumer.sh --bootstrap-server my-kafka:9092 \
	> --topic verify-test \
	> --group-id test-group
	```



## 11. kafka-delete-records.sh
	이미 적재된 토픽의 데이터를 지우는 방법.
	kafka-delete-records.sh 는 이미 적재된 토픽의 데이터중 가장 오래된 데이터부터 특정 시점의 오프셋까지 삭제 가능.

	```
	(로컬에서)
	$ vi delete-topic.json

	{"partitions": [{"topic":"test", "partition":0, "offset":50}], "version":1}
	(현재 토픽 조회해서 현재 토픽명,  파티션, 오프셋을 정확히 맞춘 후 저장해야 삭제됨.)


	(로컬에서)
	$ bin/kafka-delete-records.sh --bootstrap-server my-kafka:9092 \
	> --offset-json-file delete-topic.json
	```


	
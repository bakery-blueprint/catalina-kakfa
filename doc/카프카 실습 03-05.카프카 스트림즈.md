# **Chapter 03 "카프카 기본 개념 설명"**

### **3.5. 카프카 스트림즈**

## 1) 카프카 스트림즈란?

- 카프카는 대규모 메시지를 저장하고 빠르게 처리하기 위해 만들어짐
- 초기 사용 목적과는 다른 뛰어난 성능으로 인해 연속된 메세지인 스트림을 처리하는데도 사용되기 시작함
- 스트림 예시
    - 신용카드 거래
    - 주식 거래
    - 택배 서비스
    - 네트워크 스위치를 거쳐 발생하는 네트워크 이벤트 등 연속적인 이벤트
- 스트림 프로세싱 vs 배치 프로세싱
    - 스트림 프로세싱
        - 데이터들이 지속적으로 유입되고 나가는 과정에서 이 데이터에 대한 일련의 처리 혹은 분석을 수행
        - 실시간 분석
    - 배치 프로세싱
        - 데이터를 한 번에 특정 시간에 처리
- 스트림 프로세싱 장점
    - 이벤트에 즉각적으로 반응하기 때문에 지연 시간이 거의 발생하지 않음
    - 최신 데이터 반영
- 상태 기반 스트림 처리
    - 실시간 데이터 처리를 위해 이전에 분석된 데이터의 결과가 필요
    - 따라서 결과를 저장할 상태 저장소 필요
- 무상태 기반 스트림 처리
    - 이전 스트림의 처리 결과와 관계없이 현재 데이터로만 처리
- 이벤트 시간과 처리 시간을 분리해서 다루고 다양한 시간 간격 옵션을 지원하기 때문에 실시간 분석을 간단하지만 효율적으로 진행할 수 있음

## 2) 카프카 스트림즈의 구조

카프카 스트림즈를 사용하기 위해서는 데이터의 흐름을 표현하기 위해노드와 선으로 이루어진 토폴로지(`Topology`)라는 개념을 알아야 함

### (1) 토폴로지 (Topology)

토폴로지는 노드와 '노드와 노드를 이은 선'으로 이루어져 있는데, 노드는 프로세서(`Processor`), 선은 스트림(`Stream`)을 의미한다 .즉, 데이터를 처리하는 것이 노드이고 다음 노드로 넘어가는 데이터를 선이라고 보면 된다.

### (2) 노드, 프로세서 (Processor)

![https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F54288873-3c64-4a8c-b914-ce5c06a5fdb6%2Fimage.png](https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F54288873-3c64-4a8c-b914-ce5c06a5fdb6%2Fimage.png)

- **소스 프로세서 (Source Processor)** 토폴로지의 시작 노드이며, 데이터를 처리하기 위해 최초로 선언해야 하는 노드이다. 카프카와 연결된 프로세서이며, 하나 이상의 토픽에서 데이터를 가져오는 역할을 함
- **스트림 프로세서 (Stream Processor)** 다른 프로세서(소스 프로세서, 스트림 프로세서)가 반환한 데이터를 처리하는 역할
- **싱크 프로세서 (Sink Processor)** 토폴로지의 마지막 노드이며, 데이터 전달을 위해 마지막에 선언해야 하는 노드이다. 카프카와 연결된 프로세서이며, 데이터를 카프카의 특정 토픽으로 저장하는 역할을 함

## 3) 스트림즈를 구현하는 방법

### (1) 스트림즈 DSL

- 데이터의 흐름을 추상화한 3가지 개념 존재
- `KStream`, `KTable`, `GlobalKTable`

### 스트림즈 DSL의 데이터 흐름 추상화 개념

![https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F94556040-af90-44ab-97ac-fe6cde87f1af%2Fimage.png](https://velog.velcdn.com/images%2Fjwpark06%2Fpost%2F94556040-af90-44ab-97ac-fe6cde87f1af%2Fimage.png)

- **KStream**`KStream`으로 데이터를 조회하면 토픽에 존재하는 모든 데이터가 출력된다. 이때, 토픽에 존재하는 데이터(레코드)의 key가 동일해도 key의 중복을 허용하며 데이터를 모두 가져온다.
- **KTable**`KTable`로 데이터를 조회하면 토픽에 존재하는 데이터를 가져오면서 현재 가져온 데이터의 key가 이전에 가져온 데이터의 key와 동일한 경우에는 현재 가져온 데이터(최신 데이터)로 해당 key의 value를 변경한다.

### 4) 실습
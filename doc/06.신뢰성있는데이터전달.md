# Chapter 06 "신뢰성 있는 데이터 전달"

* 신뢰성 있는 데이터 전달은, 성능처럼 개발 초기부터 시스템에 설계되어야 한다.
* 아파치 카프카는 신뢰성 있는 데이터 전달에 관해 매우 유연하다.<br>
  즉, 애플리케이션 복잡도, 성능, 가용성, 디스크 공간 등 간의 타협점을 조정할 수 있다. (트레이등오프)

## 1. 신뢰성 보장

* 카프카는 파티션의 메시지 순서를 보장한다.
* 각 파티션의 모든 동기화 리플리카(in-sync replica, ISR: 일종의repliaction group으로 형성하여 관리)에 메시지를 썼다면, 해당 메시지는commit 된 것으로 간주한다.
* 최소한 하나의 리플리카가 살아있다면 커밋된 메시지는 유실되지 않는다.
* 컨슈머는 커밋된 메시지만 읽을 수 있다.

## 2. 복제 (replication)

*  장애 발생 시, 카프카는 다수의 리플리카에 메시지를 써서 메시지의 지속성을 제공한다.
* 리플리카가 파티션의 리더이거나 아래와 같은 팔로어일 때, 그 리플리카는 동기화되는 것으로 간주한다.
    * 주키퍼와 세션이 연결되어 있음. 즉, n초 내에 주키퍼에게 하트비트를 전송함.
    * 최근 n초 내에 리더로부터 메시지를 읽었음.
    * 최근 n초 내에 리더로부터 가장 최근 메시지를 읽었음.
* 비동기화 리플리카는 주키퍼와 다시 연결되어 리더에 저장된 가장 최근 메시지들까지 복제하면, 다시 동기화 상태가 된다.

## 3. 브로커 구성 매개변수 3가지

* 카프카에서는 토픽마다 신뢰성에 관련된 트레이드오프를 제어할 수 있기 때문에, 신뢰성이 중요한 토픽과 신뢰성보다는 다른 관점이 더 중요한 토픽 모두를 같은 카프카 클러스터에 저장할 수 있다.

### 3.1. 복제 팩터(replication.factor) / 토픽 수준

* replication.factor 가 N이면 N-1 개의 브로커가 중단되더라도 여전히 토픽의 데이터를 신뢰성 읽게 읽거나 쓸 수 있다.
    * 장점: 복제 팩터가 클수록 가용성과 신뢰성은 높아지고 장애에 따른 데이터 유실은 적어진다.
    * 단점: 최소한 N개의 브로커가 필요하고, N개의 복사본을 저장해야 하므로 N배의 디스크 공간이 필요하다.
    * 즉, 가용성을 높이는 대신 하드웨어가 더 많이 소요된다.
* 토픽에 적합한 리플리카의 갯수는 3이다.
    * 1 - 하나의 브로커가 다시 시작될 때 특정 토픽을 사용할수 없으므로, 디스크나 서버를 절약할 수는 있지만 높은 가용성은 포기해야 한다.
    * 2 - 하나의 브로커가 중단되면 클러스터가 불안정한 상태가 되어서, 나머지 다른 브로커를 다시 시작해야 하는 경우가 생기므로 가용성을 보장할 수 없는 상태가 될 수 있다.
    * 3 - 가용성이 중요한 토픽은 3으로 설정하는 것이 좋다.
* broker.rack - 랙 수준의 장애를 방지하기 위해 다수의 랙에 브로커들을 위치시킨 후 각 브로커의 랙 이름을 설정하면, 파티션의 리플리카들이 다수의 랙에 걸쳐 분산되도록 하여 가용성을 보장한다.

### 3.2. 언클린 리더 선출 (unclean.leader.election.enable) / 브로커 수준

* 클린 리더 선출(clean leader election): 파티션의 리더를 더 이상 사용할 수 없다면 동기화 리플리카 중 하나가 새로운 리더로 선출된되고, 이 경우 커밋된 데이터가 유실되지 않는다는 것이 보장된다.
* 만약 동기화 리플리카가 존재하지 않고 비동기화 리플리카만 존재한다면?
* unclean.leader.election.enable = true
    * 언클린 선출(unclean election): 비동기 리플리카를 리더가 될 수 있게 한다.
    * 해당 리플리카가 동기화가 되지 않는 동안 이전 리더에 썼던 메시지들을 잃게 될 수 있다.
    * 가용성이 더 중요한 시스템에서 사용 (예: 실시간 클릭 정보 분석)
* unclean.leader.election.enable = false
    * 해당 파티션은 이전 리더가 다시 온라인이 될 때까지 오프라인 상태로 남게 되므로 가용성이 떨어질 수 있다.
    * 데이터 품질과 일관성이 중요한 시스템에서 사용(예: 신용카드 결제 시스템)

### 3.3. 최소 동기화 리플리카 (min.insync.replicas) / 토픽&브로커 수준

* 커밋된 데이터를 하나 이상의 리플리카에 확실하게 쓰려면, min.insync.replicas 으로 최소 동기화 리플리카를 조절할 수 있다.
* 예) 하나의 토픽이 3개의 리플리카를 가질 때 min.insync.replicas = 2로 설정하면, 3개의 리플리카 중에서 최소 2개가 동기화될 때 토픽의 파티션에 쓸 수 있다.
* 위 조건이 충족되지 않을 때에는 NotEnoughReplicasException이 발생하지만, 컨슈머는 기존 데이터를 계속 읽을 수 있다.

## 4. 신뢰성 있는 시스템에서 프로듀서 사용하기

* 신뢰성 요구 사항에 맞도록 acks 구성 매개변수를 올바르게 설정해야 한다.
* 구성 매개변수와 프로듀서 코드 모두에서 에러 처리를 올바르게 해야 한다.

### 4.1. 확인 응답 전송 (ack 구성 매개변수)

* acks = 0 메시지를 보내고 확인을 하지 않는다.
* acks = 1 리더가 메시지를 썼는지 확인한다.
* acks = all 모든 동기화 리플리카에 복제되었는지 확인한다.

### 4.2. 프로듀서의 재시도 구성하기

* 프로듀서가 브로커에세 메시지를 전송하면, 브로커는 성공/에러 코드를 반환한다.<br>
  이 때, 프로듀서는 브로커가 반환하는 재시도 가능한 에러를 처리할 수 있다.
    * 재시도하면 해결될 수 있는 에러 - LEADER_NOT_AVAILABLE (새로운 브로커가 리더로 선출되었을 것이므로 두 번쨰 시도는 성공할 것)
    * 재시도 불가능한 에러 - INVALID_CONFIG
* retries 매개변수로 재시도 횟수를 조절한다.
* 메시지 재전송 시도시, 각 메시지가 최소 한 번 저장되는 것을 보장할 수 는 있지만, 정확히 한 번만 저장된다는 것은 보장되지 않는다.
* 따라서, 각 메시지에 고유 식별자를 추가하여 중복을 찾아내고 메시지를 읽을 때 걸러내도록 한다.

### 4.3. 추가적인 에러 처리

* 개발자가 프로듀서 라이브러리를 사용해서 처리해야 하는 에러도 있다.
    * 메시지 크기, 인증 에러 등과 같이 재시도 불가능한 브로커 에러
    * 메시지가 브로커에게 전송되기 전에 발생한 에러. 예) 직렬화

## 5. 신뢰성 있는 시스템에서 컨슈머 구성하기

* 컨슈머가 메시지를 다시 읽을 때는 마지막으로 커밋된 오프셋을 기준으로 읽으므로, 컨슈머는 작업을 완료한 후 오프셋을 커밋해야 한다.
* 작업을 완료하기 전에 오프셋을 커밋했는데, 이후 작업 도중 문제가 생긴다면 문제가 생겼던 메시지는 넘어가게 되는 문제가 있다.

### 5.1. 신뢰성 있는 처리에 중요한 컨슈머 구성 속성 4가지

* group.id: 두 개의 컨슈머가 같은 그룹 ID를 갖는다면, 각 컨슈머는 할당받은 파티션의 메시지만 읽게 된다. (그룹 전체로는 모든 메시지를 읽게 됨)
* auto.offset.reset: 커밋된 오프셋이 없을 때 (예: 컨슈머가 처음 시작할 때) 컨슈머를 제어한다.
    * earliest: 해당 파티션의 맨 앞부터 모든 데이터를 읽는다.
    * latest(기본값): 해당 파티션의 제일 끝부터 읽기 시작한다.
* enable.auto.commit: n초마다 오프셋 커밋을 자동으로 할 것인지(true), 코드에서 직접 할 것인지(false)를 지정한다.
* auto.commit.interval.ms: 위의 n초를 설정한다.

### 5.2. 컨슈머에서 오프셋 커밋할 때 고려할 사항

* 오프셋 커밋은 항상 메시지가 처리된 후에 하자.
* 오프셋 커밋 빈도는 성능과 중복 메시지 개수 간의 트레이드 오프이다.
* 처리된 메시지의 오프셋을 커밋하는 것이 중요하다.
* 어플리케이션을 설계할 때는 컨슈머 리밸런싱이 수행될 수 있고, 이 때 오프셋을 커밋하는 등 적합하게 처리해야 한다.
* 만약 컨슈머가 상태 데이터를 유지해야 하는 경우는 특정 토픽을 따로 만들어서 여기로 메시지를 보내고, 컨슈머 스레드가 시작될 때 메시지를 가져와 마지막 값을 찾도록 한다.
* 카프카에서 읽은 레코드 처리에 시간이 오래 걸릴 경우, 레코드를 스레드풀에 전달하여 처리하게 한다.
* 현재의 카프카 버전에서는 At-least-once(최소 한 번) 전송은 지원하지만, Excatly-once(정확히 한번) 전송은 완벽하게 지원하지 않는다. <br>
  At-least-once 전송을 하기 위해 고유 키를 지원하는 외부 시스템에 식별 데이터를 쓰는 방법이 있다.

## 6. 시스템 신뢰성 검사하기 3단계

### 6.1. 구성 검사하기

* 카프카에서는 브로커와 클라이언트 구성을 테스트하기 위해 아래와 같은 도구를 지원한다.
    * org.apache.kafka.tools.VerifiableProducer
    * org.apache.kafka.tools.VerifiableConsumer
* 테스트 시나리오 예시
    * 리더 선출: 리더를 중단시키면 어떻게 될까? 다시 작동하는데 얼마나 걸릴까?
    * 컨트롤러 선출: 컨트롤러를 다시 시작시킨 후 시스템이 재개되는데 얼마나 걸릴까?
    * 단계적 재시작: 메시지 유실 없이 브로커를 하나씩 재시작시킬 수 있을까?
    * 언클린 리더 선출 테스트: 한 파티션의 모든 리플리카들을 하나씩 중단시킨 다음에, 비동기화되었던 브로커를 시작시키면 어떻게 될까?

### 6.2. 애플리케이션 검사하기

* 애플리케이션에서 신뢰성을 보장하는지 테스트한다.
* 에러 처리 코드, 오프셋 커밋, 리밸런싱 리스너, 카프카의 클라이언트 라이브러리와 상호작용하는 애플리케이션 로직 등을 확인한다.
* 테스트 시나리오 예시
    * 클라이언트와 서버 간의 연결이 끊어짐
    * 리더 선출
    * 브로커/컨슈머/프로듀서들을 중단시킨 후 하나씩 다시 시작함

### 6.3. 실제 업무 운용 시의 신뢰성 모니터링하기

* 프로듀서가 쓴 모든 데이터를 시기적절하게 컨슈머가 읽는 지를 확인해야 한다.
    * 프로듀서 측면 - 에러율, 재시도율
    * 컨슈머 측면 - 컨슈머의 처리 지연(lag)